<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Reinforcement Learning Quantum State Preparation</title>
  <meta name="description" content="A Reinforcement Learning agent learns to Prepare Quantum States in a non-integrable Ising chain. With noprior knowledge about the quantum system, the agent l...">

  <link rel="canonical" href="http://localhost:4000/ml/2017/04/01/ML.html">
  <link rel="alternate" type="application/rss+xml" title="Marin Bukov, PhD" href="http://localhost:4000/feed.xml" />

  <!-- Material Design Lite css Library -->
  <link rel="stylesheet" type="text/css" href="https://storage.googleapis.com/code.getmdl.io/1.0.0/material.indigo-pink.min.css">
  
  <!-- Material Design Fonts -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/icon?family=Material+Icons">

  <!-- Custom theme css -->
  <link rel="stylesheet" href="/css/main.css">

  <!-- Google analytics -->
  
</head>


  <body>

    <!-- Start Layout -->
    
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
      <!-- search layout -->
<div class="super-search" id="js-search">
  <ul class="super-search__results" id="js-search__results"></ul>        
  <button class="mdl-button mdl-js-button mdl-button--fab mdl-button--colored super-search__close-btn" onclick="superSearch.toggle()">
    <i class="material-icons">close</i>
  </button>
</div>
<!-- /end search -->
        <header class="mdl-layout__header">

    <div class="mdl-layout__header-row">
      <!-- Title -->
      <span class="mdl-layout-title">Marin Bukov, PhD</span>
      <!-- Add spacer, to align navigation to the right -->
      <div class="mdl-layout-spacer"></div>
      

      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable is-upgraded">
        <label class="mdl-button mdl-js-button mdl-button--icon" for="js-search__input">
          <i class="material-icons">search</i>
        </label>

        <div class="mdl-textfield__expandable-holder" >
          <input class="mdl-textfield__input super-search__input" type="text" id="js-search__input" />
        </div>
      </div>
      
      <button class="mdl-button mdl-js-button mdl-button--icon" id="menu-lower-left">
        <i class="material-icons">more_vert</i>
      </button>

      <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="menu-lower-left">
        
        <li><a href="https://scholar.google.com/citations?user=xRJLNpAAAAAJ&hl=en" class="mdl-menu__item">Google Scholar</a></li>
        
        <li><a href="https://arxiv.org/find/cond-mat/1/au:+Bukov_M/0/1/0/all/0/1" class="mdl-menu__item">Publications</a></li>
        
      </ul>
    </div>
  </header>

  <div class="mdl-layout__drawer">
    <span class="mdl-layout-title">Menu</span>
    <nav class="mdl-navigation">
    <a class="mdl-navigation__link" href="/">HOME</a>
    
      
      <a class="mdl-navigation__link" href="/CV/">CV</a>
      
    
      
    
      
    
      
    
    
      
    
      
      <a class="mdl-navigation__link" href="/control_phases/2017/08/20/control_phases.html">Phase Transitions of Quantum Control</a>
      
    
      
      <a class="mdl-navigation__link" href="/ml/2017/04/01/ML.html">Reinforcement Learning Quantum State Preparation</a>
      
    
      
      <a class="mdl-navigation__link" href="/floquet/2017/01/22/floquet.html">Periodically Driven Systems</a>
      
    
      
      <a class="mdl-navigation__link" href="/quspin/2016/09/01/quspin.html">QuSpin</a>
      
    
    </nav>

  </div>


    

    <div class="post-ribbon"></div>
<main class="post-main mdl-layout__content">
  <div class="post-container mdl-grid">
    <div class="mdl-cell mdl-cell--2-col mdl-cell--hide-tablet mdl-cell--hide-phone"></div>
    <div class="post-section mdl-color--white mdl-shadow--4dp content mdl-color-text--grey-800 mdl-cell mdl-cell--8-col">
      <div class="mdl-color-text--grey-500">
      Apr 1, 2017 • Reinforcement Learning Quantum State Preparation • Marin Bukov •  ML  
      </div>
      <h3>Reinforcement Learning Quantum State Preparation</h3>
      <article class="post-content">
        <p><p>A <strong><em>Reinforcement Learning</em></strong> agent learns to <strong><em>Prepare Quantum States</em></strong> in a non-integrable Ising chain. With no
prior knowledge about the quantum system, the agent learns to extract the essential features of the optimal preparation protocol.</p>

<p>Machine Learning (ML) ideas have recently been applied to physics to detect phase transitions <span style="color:blue">[1]</span>, and extract the essence of quantum mechanical wavefunctions <span style="color:blue">[2]</span>. I have recently become interested in developing and applying Reinforcement Learning (RL) algorithms to study quantum dynamics. RL is a subfield of ML where a computer agent is taught to master a specific task by performing a series of actions in order to maximize a reward function. RL was used in the 90’s to create a computer agent to beat the world’s best backgammon players <span style="color:blue">[3]</span>. Recently, Google DeepMind succeeded in teaching a RL agent to play the video games Atari and Go <span style="color:blue">[4,5]</span>. Inspired by this success, we decided to investigate what insights in physics can be gained from such an approach.</p>

<table class="image" align="center">
<caption align="bottom"><i>Our computer agent learning how to prepare a target state for a single qubit [7].</i></caption>
<tr><td>
	<video width="504" height="326" preload="none" controls="" poster="/img/RL_bloch.png">
		<source src="/movies/qubit.mp4" />
		<source src="/movies/qubit.ogv" />
		<source src="/movies/qubit.webm" />
	</video>
</td></tr>
</table>
<p><br />
<strong><em>How does it Work?</em></strong>—We used a modified version of Watkins online Q-learning algorithm with linear function approximation and eligibility traces <span style="color:blue">[6]</span> to teach a RL agent to find an optimal protocol sequence to prepare a quantum system in a pre-defined target state <span style="color:blue">[7]</span>. To manipulate the system, our computer agent constructs piecewise-constant protocols of duration \(T\) by choosing a drive protocol strength \(h_x(t)\) at each discrete time step \(t\). One can think of \(h_x(t)\) as a magnetic field applied to the system or, more generally — as a control knob. In order to make the agent learn, it is given a reward for every protocol it constructs – the fidelity \( F_h(T)=\lvert \langle\psi_\ast \vert \psi(T)\rangle
\rvert ^2 \) for being in the target state after time \(T\) following the protocol \(h_x(t)\) <em>obeying the laws of Quantum Dynamics</em>. The goal of the agent is to maximize the reward \( F_h(T)\) in a series of attempts. Deprived of any knowledge about the underlying physical model, the agent collects information about already tried protocols, based on which it constructs new, improved protocols through a sophisticated biased sampling algorithm[RL paper]. For simplicity, consider bang-bang protocols, (see Fig.), where \(h_x(t)\in\{\pm 4\}\), although we verified that RL also works for quasi-continuous protocols with many different protocol steps. You can learn more about our work in <a href="https://arxiv.org/abs/1705.00565">this paper</a>.</p>

<table class="image" align="right">
<caption align="bottom" style="text-align:center"><i>Bang-bang protocols found by the RL agent for the single qubit (red) and the corresponding variational protocols (blue) [7].</i>
</caption>
<tr><td><img align="right" src="/img/RL_protocols.png" alt="Drawing" style="width: 320px;" /></td></tr>
</table>
<p><strong><em>Model</em></strong>—To test the agent, we decided to prepare states in the transverse-field Ising chain:</p>

<script type="math/tex; mode=display">H(t) = -\sum_{j=1}^L \left( JS^z_{j+1}S^z_j + S^z_j + h_x(t)S^x_j\right)</script>

<p>To make the model untractable by perturbative analytical calculations, we add a parallel field and choose all couplings to be of the same order of magnitude so there is no small paramter. This model is known to be nonintegrable, and features thermalising (chaotic) dynamics. We choose the paramagnetic ground states of the above Hamiltonian at fields \(h_x/J=-2\) and \(h_x/J=2\) for the initial and target state, respectively. Even though there is only one control field in the problem, the space of available protocols grows exponentially with the inverse time step size and we have demonstrated numerically that it is exponentially hard to find the optimal protocol <span style="color:blue">[8]</span>.</p>

<p><strong><em>Constrained Qubit Manipulation</em></strong>—To benchmark the performace of the RL agent, let us first set \(J=0\), so that the model decouples into a sequence of independent quantum bits, known as qubits. The movie above below shows the learning process of the RL agent for a single qubit. Notice that the protocol the agent finds after a series of attempts has a remarkable feature: without any prior knowledge about the intermediate quantum state nor its Bloch sphere representation [an effective geometric description for the quantum degrees of freedom of a single qubit], the RL agent discovers that it is advantageous to first bring the state to the equator – which is a geodesic – and then effectively turns off the field \(h_x(t)\), to enable the fastest possible precession about the \(\hat z\)-axis. After staying on the equator for as long as optimal, the agent rotates as fast as it can to bring the state as close as possible to the target, thus optimizing the final fidelity for the available protocol duration.</p>

<table class="image" align="center">
<caption align="bottom"><i>Learning how to prepare a target state in a system of many coupled qubits [7].</i></caption>
<tr><td>
	<video width="504" height="326" preload="metadata" controls="">
		<source src="/movies/many_qubits.mp4#t=0.3" />
		<source src="/movies/many_qubits.ogv#t=0.3" />
		<source src="/movies/many_qubits.webm#t=0.3" />
	</video></td></tr>
</table>
<p><br />
<strong><em>Many Coupled Qubits</em></strong>—Back to the non-integrable model \(J=1\), it is impossible to visualise the driving protocol due to the exponentially many degrees of freedom in the problem. However, by putting the system on a closed chain and making use of translation invariance, all qubits behave in the same way on every lattice site. Hence, we can trace out all sites but one, and study the properties of the underlying reduced density matrix of the remaining qubit on the Bloch sphere. The second movie shows how our RL agent learns the physics of the many-body system. This counter-intuitive solution can also be found using optimal control algorithms, such as GRAPE <span style="color:blue">[9]</span>, and hints towards the existence of bizzare principles that govern the physics of systems away from equilibrium.</p>

<p><em>References</em>:<br />
<a href="https://www.nature.com/nphys/journal/v13/n5/full/nphys4035.html" style="color: #0000cd">[1] J. Carrasquilla and R. G. Melko, <em>Nat. Phys.</em> <strong>13</strong>, 431 (2017).</a><br />
<a href="http://science.sciencemag.org/content/355/6325/602" style="color: #0000cd">[2] G. Carleo and M. Troyer, <em>Science</em> <strong>355</strong>, 602 (2017).</a><br />
<a href="http://dl.acm.org/citation.cfm?doid=203330.203343" style="color: #0000cd">[3] G. Tesauro, <em>Communications of the ACM.</em> <strong>38</strong> (3) (1995).</a><br />
<a href="https://www.nature.com/nature/journal/v518/n7540/full/nature14236.html" style="color: #0000cd">[4] V. Mnih <em>et al.</em>, <em>Nature</em> <strong>518</strong>, 529 (2015), letter.</a><br />
<a href="https://www.nature.com/nature/journal/v518/n7540/full/nature14236.html" style="color: #0000cd">[5] D. Silver,<em>et al.</em>, <em>Nature</em> <strong>529</strong>, 484 (2016), article.</a><br />
<a href="http://people.inf.elte.hu/lorincz/Files/RL_2006/SuttonBook.pdf" style="color: #0000cd">[6] R. S. Sutton and A. G. Barto, <em>Reinforcement Learning: An Introduction</em> (MIT Press, Cambridge, MA, 2017).</a><br />
<a href="https://arxiv.org/abs/1705.00565" style="color: #0000cd">[7] <strong>M.B.</strong>, A.G.R. Day, D. Sels, P. Weinberg, A. Polkovnikov, P. Mehta, <em>arXiv: 1705.00565</em> (2017).</a><br />
<a href="" style="color: #0000cd">[8] A.G.R. Day, <strong>M.B.</strong>, P. Weinberg, A. Polkovnikov, P. Mehta, and D. Sels, <em>in preparation</em> (2017).</a><br />
<a href="" style="color: #0000cd">[9] N. Khaneja, T. Reiss, C. Kehlet, T. Schulte-Herbrüggen, and S. J. Glaser, <em>Journal of Magnetic Resonance</em> <strong>172</strong>, 296 (2005).</a></p>

<p>Copyright © 2017 Marin Bukov</p>
</p>
      </article>
      <!-- Disqus comments -->
      
      <script type="text/javascript"
      src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
      </script>
    </div>
  </div>
</main>

    <footer class="mdl-mega-footer">
  <div class="mdl-mega-footer--middle-section">

    <div class="mdl-mega-footer--drop-down-section">
      <input class="mdl-mega-footer--heading-checkbox" type="checkbox" checked>
      <h1 class="mdl-mega-footer--heading">CONTACT</h1>
      <ul class="mdl-mega-footer--link-list">
        <li><a >mgbukov(at)berkeley.edu</a></li>
        <!--
        <li><a href="mailto:mgbukov(at)berkeley.edu">mgbukov(at)berkeley.edu</a></li>
        <li><a href="/feed.xml">subscribe via RSS</a></li>
        -->
      </ul>
    </div>

    <div class="mdl-mega-footer--drop-down-section">
      <input class="mdl-mega-footer--heading-checkbox" type="checkbox" checked>
      <h1 class="mdl-mega-footer--heading">ADDRESS</h1>
      <ul class="mdl-mega-footer--link-list">
        <li><a href="https://www.google.com/maps/place/LeConte+Hall/@37.8726631,-122.2575264,15z/">Department of Physics <br> University of California, Berkeley <br> office 339 <br> 366 LeConte Hall MC 7300 <br> Berkeley, CA 94720-7300</a></li>
      </ul>
    </div>

    <div class="mdl-mega-footer--drop-down-section">
      <input class="mdl-mega-footer--heading-checkbox" type="checkbox" checked>
      <h1 class="mdl-mega-footer--heading">SOCIAL</h1>
      <ul class="mdl-mega-footer--link-list">
        
        <li>
          <a href="https://github.com/mgbukov">
            <span class="icon  icon--github">
              <svg viewBox="0 0 16 16">
                <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>

            <span class="username">mgbukov</span>
          </a>
        </li>
        
        

	  

      
	  


      
        <li>
          <a href="https://www.linkedin.com/in/marin-bukov-80b69312a">
            <span class="icon  icon--linkedin">
              <svg style="width:16px;height:16px" viewBox="0 0 24 24">
                <path fill="#000000" d="M3,20.5V3.5C3,2.91 3.34,2.39 3.84,2.15L13.69,12L3.84,21.85C3.34,21.6 3,21.09 3,20.5M16.81,15.12L6.05,21.34L14.54,12.85L16.81,15.12M20.16,10.81C20.5,11.08 20.75,11.5 20.75,12C20.75,12.5 20.53,12.9 20.18,13.18L17.89,14.5L15.39,12L17.89,9.5L20.16,10.81M6.05,2.66L16.81,8.88L14.54,11.15L6.05,2.66Z" />
              </svg>
            </span>

            <span class="username">LinkedIn</span>
          </a>
        </li>
      
	  
      </ul>
    </div>

    <!--
    <div class="mdl-mega-footer--drop-down-section">
      <input class="mdl-mega-footer--heading-checkbox" type="checkbox" checked>
      <h1 class="mdl-mega-footer--heading">ABOUT</h1>
      <ul class="mdl-mega-footer--link-list">
        <li>I study the dynamics of out-of-equilibrium many-body quantum and classical systems. My research focusses on  Condensed Matter Physics, Ultracold Atoms, and Statistical Mechanics, and the interplay between Machine Learning and Physics. 
</li>
      </ul>
    </div>
    -->

  </div>

  <div class="mdl-mega-footer--bottom-section">
    <div class="mdl-logo">Marin Bukov, PhD</div>
    <!--
    <ul class="mdl-mega-footer--link-list">
      <li><a href="#">Help</a></li>
      <li><a href="#">Privacy & Terms</a></li>
    </ul>
    -->
  </div>

</footer>


    </div>
    <!-- /End Layout -->

    <!-- Material Design Lite js Library -->
    <script type="text/javascript" src="https://storage.googleapis.com/code.getmdl.io/1.0.0/material.min.js"></script>
    
    <script rel="javascript" type="text/javascript" src="/js/search.js"></script>
    <script rel="javascript" type="text/javascript">
      superSearch({
        searchFile: '/feed.xml',
        searchSelector: '#js-search', // CSS Selector for search container element.
        inputSelector: '#js-search__input', // CSS selector for <input>
        resultsSelector: '#js-search__results' // CSS selector for results container
      });
    </script>
  </body>

</html>
